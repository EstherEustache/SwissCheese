# generateNA <- function(X, pp, nr_min)
# {
#   #----Response indicator matrix: r
#   r <- matrix(rep(TRUE, nrow(X)*ncol(X)), dim(X))
#   while(sum(rowSums(r)!=5)<nr_min){
#     r <- array(runif(nrow(pp)*ncol(pp)),dim(pp))<pp
#   }
#   #----Add NA to matrix X
#   X[!r] <- NA
#   return(X)
# }
########################################################
# generateNA <- function(X)
# {
#   prop_missing <- 0.5
#
#   X    <- as.matrix(X)
#   S    <- diag(1/sqrt(diag(var(X))))
#   XX   <- X%*%S
#   XXX  <- (XX-rep(1,nrow(XX))%*%t(apply(XX,2,min)))
#   x    <- rowSums(XXX)
#   prob <- inclusionprobabilities(x,round(length(x)*prop_missing))
#   nr   <- UPrandomsystematic(prob)
#
#   XNR  <- X
#   p    <- ncol(X)
#   for(i in 1:nrow(X)) if(nr[i]==1) XNR[i,sample(p,rdunif(1,1,p-1))]=NA
#   return(XNR)
# }
########################################################
generateNA <- function(X)
{
for(i in 1:5){
miss  <- 0.1
y     <- X[,i]
yy    <- y-min(y)
p     <- inclusionprobabilities(yy+mean(yy)/n,n*miss)
y[runif(n)<p] <- NA
X[,i] <- y
}
return(X)
}
##----------------------------------------------------------------
##                    Function for simulations                   -
##----------------------------------------------------------------
funImput <- function(imput_i, df, X_NA, d){
X <- df
generateNA <- function(X)
{
for(i in 1:5){
miss  <- 0.1
y     <- X[,i]
yy    <- y-min(y)
p     <- inclusionprobabilities(yy+mean(yy)/n,n*miss)
y[runif(n)<p] <- NA
X[,i] <- y
}
return(X)
}
X_NA <- generateNA(X)
##--------------
##  Imputation
##--------------
k    <- 5
#---Swiss cheese imputation with linear programming (deterministic)
X_LI <- deterministicImput(X_NA, d = NULL, k = k)
#---Swiss cheese imputation with linear programming (random)
X_LP <- lpSwissCheeseImput(X_NA, d = NULL, k = k)
#---Swiss cheese imputation with linear programming (deterministic)
X_LI1 <- deterministicImput(X_NA, d = NULL, k = NULL)
#---Swiss cheese imputation with linear programming (random)
X_LP1 <- lpSwissCheeseImput(X_NA, d = NULL, k = NULL)
#---Imputation by the mean of the knn
X_KN <- knnImput(X_NA, k = k)
#---Imputation by the nearest neighbors
X_NN <- knnImput(X_NA, k = 1)
##-----------
##  Results
##-----------
#--- Compute for each variable and each imputation method: total, 10-th and 90-th percentile, median, variance.
tot       <- as.vector(colSums(X))
tot_KN    <- as.vector(colSums(X_KN))
tot_NN    <- as.vector(colSums(X_NN))
tot_LI    <- as.vector(colSums(X_LI))
tot_LP    <- as.vector(colSums(X_LP))
tot_LI1    <- as.vector(colSums(X_LI1))
tot_LP1    <- as.vector(colSums(X_LP1))
P25       <- as.vector(apply(X,    2, quantile, probs = 0.25))
P25_KN    <- apply(X_KN, 2, quantile, probs = 0.25)
P25_NN    <- apply(X_NN, 2, quantile, probs = 0.25)
P25_LI    <- apply(X_LI, 2, quantile, probs = 0.25)
P25_LP    <- apply(X_LP, 2, quantile, probs = 0.25)
P25_LI1    <- apply(X_LI1, 2, quantile, probs = 0.25)
P25_LP1    <- apply(X_LP1, 2, quantile, probs = 0.25)
P75       <- as.vector(apply(X,    2, quantile, probs = 0.75))
P75_KN    <- apply(X_KN, 2, quantile, probs = 0.75)
P75_NN    <- apply(X_NN, 2, quantile, probs = 0.75)
P75_LI    <- apply(X_LI, 2, quantile, probs = 0.75)
P75_LP    <- apply(X_LP, 2, quantile, probs = 0.75)
P75_LI1    <- apply(X_LI1, 2, quantile, probs = 0.75)
P75_LP1    <- apply(X_LP1, 2, quantile, probs = 0.75)
P50       <- as.vector(apply(X,    2, quantile, probs = 0.50))
P50_KN    <- apply(X_KN, 2, quantile, probs = 0.50)
P50_NN    <- apply(X_NN, 2, quantile, probs = 0.50)
P50_LI    <- apply(X_LI, 2, quantile, probs = 0.50)
P50_LP    <- apply(X_LP, 2, quantile, probs = 0.50)
P50_LI1    <- apply(X_LI1, 2, quantile, probs = 0.50)
P50_LP1    <- apply(X_LP1, 2, quantile, probs = 0.50)
#---All results
Estimate_simu <- c(tot, tot_KN, tot_NN, tot_LI, tot_LP, tot_LI1, tot_LP1,
P25, P25_KN, P25_NN, P25_LI, P25_LP, P25_LI1, P25_LP1,
P50, P50_KN, P50_NN, P50_LI, P50_LP, P50_LI1, P50_LP1,
P75, P75_KN, P75_NN, P75_LI, P75_LP, P75_LI1, P75_LP1)
return(Estimate_simu)
}
##----------------------------------------------------------------
##                    parallelized simulations                   -
##----------------------------------------------------------------
library(parallel)
#---- Define cluster
#cl <- makeCluster(detectCores())
cl <- makeCluster(3)
clusterEvalQ(cl,{
#---packages for simulations
devtools::load_all(".")
library(sampling)
library(StratifiedSampling)
})
#----Number of simulations
nb_nr     <- 200  #---Number of random nonresponse
nb_method <- 4
funImput <- function(imput_i, df, d){
X <- df
generateNA <- function(X)
{
n <- nrow(X)
for(i in 1:5){
miss  <- 0.1
y     <- X[,i]
yy    <- y-min(y)
p     <- inclusionprobabilities(yy+mean(yy)/n,n*miss)
y[runif(n)<p] <- NA
X[,i] <- y
}
return(X)
}
X_NA <- generateNA(X)
##--------------
##  Imputation
##--------------
k    <- 5
#---Swiss cheese imputation with linear programming (deterministic)
X_LI <- deterministicImput(X_NA, d = NULL, k = k)
#---Swiss cheese imputation with linear programming (random)
X_LP <- lpSwissCheeseImput(X_NA, d = NULL, k = k)
#---Swiss cheese imputation with linear programming (deterministic)
X_LI1 <- deterministicImput(X_NA, d = NULL, k = NULL)
#---Swiss cheese imputation with linear programming (random)
X_LP1 <- lpSwissCheeseImput(X_NA, d = NULL, k = NULL)
#---Imputation by the mean of the knn
X_KN <- knnImput(X_NA, k = k)
#---Imputation by the nearest neighbors
X_NN <- knnImput(X_NA, k = 1)
##-----------
##  Results
##-----------
#--- Compute for each variable and each imputation method: total, 10-th and 90-th percentile, median, variance.
tot       <- as.vector(colSums(X))
tot_KN    <- as.vector(colSums(X_KN))
tot_NN    <- as.vector(colSums(X_NN))
tot_LI    <- as.vector(colSums(X_LI))
tot_LP    <- as.vector(colSums(X_LP))
tot_LI1    <- as.vector(colSums(X_LI1))
tot_LP1    <- as.vector(colSums(X_LP1))
P25       <- as.vector(apply(X,    2, quantile, probs = 0.25))
P25_KN    <- apply(X_KN, 2, quantile, probs = 0.25)
P25_NN    <- apply(X_NN, 2, quantile, probs = 0.25)
P25_LI    <- apply(X_LI, 2, quantile, probs = 0.25)
P25_LP    <- apply(X_LP, 2, quantile, probs = 0.25)
P25_LI1    <- apply(X_LI1, 2, quantile, probs = 0.25)
P25_LP1    <- apply(X_LP1, 2, quantile, probs = 0.25)
P75       <- as.vector(apply(X,    2, quantile, probs = 0.75))
P75_KN    <- apply(X_KN, 2, quantile, probs = 0.75)
P75_NN    <- apply(X_NN, 2, quantile, probs = 0.75)
P75_LI    <- apply(X_LI, 2, quantile, probs = 0.75)
P75_LP    <- apply(X_LP, 2, quantile, probs = 0.75)
P75_LI1    <- apply(X_LI1, 2, quantile, probs = 0.75)
P75_LP1    <- apply(X_LP1, 2, quantile, probs = 0.75)
P50       <- as.vector(apply(X,    2, quantile, probs = 0.50))
P50_KN    <- apply(X_KN, 2, quantile, probs = 0.50)
P50_NN    <- apply(X_NN, 2, quantile, probs = 0.50)
P50_LI    <- apply(X_LI, 2, quantile, probs = 0.50)
P50_LP    <- apply(X_LP, 2, quantile, probs = 0.50)
P50_LI1    <- apply(X_LI1, 2, quantile, probs = 0.50)
P50_LP1    <- apply(X_LP1, 2, quantile, probs = 0.50)
#---All results
Estimate_simu <- c(tot, tot_KN, tot_NN, tot_LI, tot_LP, tot_LI1, tot_LP1,
P25, P25_KN, P25_NN, P25_LI, P25_LP, P25_LI1, P25_LP1,
P50, P50_KN, P50_NN, P50_LI, P50_LP, P50_LI1, P50_LP1,
P75, P75_KN, P75_NN, P75_LI, P75_LP, P75_LI1, P75_LP1)
return(Estimate_simu)
}
#----Number of simulations
nb_nr     <- 200  #---Number of random nonresponse
nb_method <- 4
l <- parLapply(cl = cl,
X = 1:nb_nr,
fun = funImput,
df = X,
d = NULL)
l
#----store the results
res <- matrix(unlist(l), nrow = nb_nr, byrow = TRUE)
# write.csv(res, file='C:\\Users\\eustachee\\switchdrive\\Swiss cheese\\subject_1\\Simulation\\results_1\\estim.csv')
write.csv(res, file='M:\\Projet_swiss_cheese\\simulations\\results\\res_5.csv')
resultSimu <- function(param,J) {
n <- nrow(param)
#############
theta       <- param[1,1:J] #----only one row because there are all equal (true value)
#---Bias and RMSE of the estimate parameter of simulations (ex: total, P10, etc)
#-------Bias
#-------Relative bias
Bias <- matrix(rep(0,J*nb_method), ncol = J)
for(i in 2:(nb_method+1)){
Bias[(i-1),]   <- as.numeric(colMeans(param[,((i-1)*J+1):(i*J)])   - theta)
}
#B <- t(apply(Bias[-1,], 1, function(x){ x/Bias[1,]*100 }))
B <- Bias
#-------MSE+variance of the estimate parameter of simulations (ex: total, P10, etc)
#-------MSE+variance of the estimate parameter of simulations (ex: total, P10, etc)
RMSE  <- matrix(rep(0,J*nb_method), ncol = J)
for(i in 2:(nb_method+1)){
#--MSE
RMSE[(i-1),] <- colMeans((param[,((i-1)*J+1):(i*J)]   - rep(1,nb_nr)%*%as.matrix(theta))^2)
}
MSE <- RMSE
#-------Final results
B    <- round(B,    2)
MSE  <- round(MSE,  2)
return(list(B = B, MSE = MSE))
}
#---Download results
# path <- 'C:\\Users\\eustachee\\switchdrive\\Swiss cheese\\subject_1\\Simulation\\results_18\\'
path <- 'M:\\Projet_swiss_cheese\\simulations\\results\\'
df <- read.csv(paste0(path,'res_5.csv'))[,-1]
#---Each parameter
nb_method <- 6 # number of methods compared
tot <- (0*(nb_method+1)*J+1):(1*(nb_method+1)*J)
P25 <- (1*(nb_method+1)*J+1):(2*(nb_method+1)*J)
P50 <- (2*(nb_method+1)*J+1):(3*(nb_method+1)*J)
P75 <- (3*(nb_method+1)*J+1):(4*(nb_method+1)*J)
##penser à updater nb_imput
nb_nr <- 200
J <- 5
param_tot <- df[,tot]
resTot    <- resultSimu(param = param_tot, J) # à adapter en fonction des méthodes à comparer
resTot
df_tot           <- rbind(as.matrix(resTot$B), as.matrix(resTot$MSE))
rownames(df_tot) <- c("KNN", "NN", "LP\\_prev", "LP\\_cube", "LP\\_prev_1", "LP\\_cube_1",
"KNN", "NN", "LP\\_prev", "LP\\_cube", "LP\\_prev_1", "LP\\_cube_1")
df_tot
cor(X)
lm(X[,1]~X[,2:5])
res <- lm(X[,1]~X[,2:5])
res$coefficients
summary(lm(X[,1]~X[,2:5]))
summary(lm(X[,2]~X[,c(1,3,4,5)]))
summary(lm(X[,3]~X[,c(1,2,4,5)]))
summary(lm(X[,4]~X[,c(1,2,3,5)]))
summary(lm(X[,5]~X[,c(1,2,3,4)]))
library(fastDummies)
library(survey)
data("api")
head(apipop)
#--Variables with no missing values
X   <- apipop[,which(as.numeric(apply(apipop, 2, function(x) !any(is.na(x)))) == 1)]
X   <- X[,-c(1,3,4,5,6,8)]
X   <- dummy_columns(X, remove_first_dummy = TRUE, remove_selected_columns = TRUE)
X   <- X[,c(5,6,13,14,15)]
#X   <- cbind(X$growth, X$meals, X$grad.sch, X$ell, X$awards_Yes)
set.seed(1)
s   <- sample(1:nrow(X), 500)
X   <- X[s,]
X <- as.matrix(X)
rownames(X) <- NULL
colnames(X) <- NULL
N <- nrow(X)
J <- ncol(X)
summary(lm(X[,1]~X[,2:5]))
summary(lm(X[,2]~X[,c(1,3,4,5)]))
summary(lm(X[,3]~X[,c(1,2,4,5)]))
summary(lm(X[,4]~X[,c(1,2,3,5)]))
summary(lm(X[,5]~X[,c(1,2,3,4)]))
cor(X)
?install.packages
I_tmp  <- matrix(rep(0, length(larger*100*400)), nrow = length(larger), ncol = 100*400)
I_tmp  <- matrix(rep(0, length(2*100*400)), nrow = length(2), ncol = 100*400)
I_tmp
head(I_tmp)
res <- na.omit(X)
res
na.omit(X)
apply(X, 1, function(x) any(is.na(X)))
?rep
200*300
apply(X, 2, function(x) std(x) == 0)
apply(X, 2, function(x) sd(x) == 0)
any(apply(X, 2, function(x) sd(x) == 0))
!any(apply(X, 2, function(x) sd(x) == 0))
var_0 <- apply(X, 2, function(x) sd(x) == 0))
var_0 <- apply(X, 2, function(x) sd(x) == 0)
var_0
var_0 <- !apply(X, 2, function(x) sd(x) == 0)
var_0
which(var_0)
var_0 <- which(!apply(X, 2, function(x) sd(x) == 0))
var_0
X
X <- generateNA(X)
#--- Standardized data
X_init <- X
var_0 <- which(!apply(X, 2, function(x) sd(x) == 0))
X0 <- X[,var_0]
for(i in var_0){
X0[!is.na(X[,i]),i] <- as.vector(scale(X0[!is.na(X0[,i]),i]))
}
X0
head(X)
library(sampling)
#library(purrr)
p    <- 3
n    <- 300
beta <- rep(1,p)
beta2 <- runif(p)*2
miss <- 0.3
X <- matrix(rnorm(p*n),c(n,p))
y <- X%*%beta+rnorm(n)
y2 <- X%*%beta2+rnorm(n)
X <- cbind(X,y,y2)
# X <- cbind(X,y)
N <- nrow(X)
J <- ncol(X)
generateNA <- function(X)
{
for(i in 1:5){
miss  <- 0.1
y     <- X[,i]
yy    <- y-min(y)
p     <- inclusionprobabilities(yy+mean(yy)/n,n*miss)
y[runif(n)<p] <- NA
X[,i] <- y
}
return(X)
}
X <- generateNA(X)
##------------------
##  Initialization
##------------------
eps <- 1e-4
#--- Standardized data
X_init <- X
var_0 <- which(!apply(X, 2, function(x) sd(x) == 0))
X0 <- X[,var_0]
for(i in var_0){
X0[!is.na(X[,i]),i] <- as.vector(scale(X0[!is.na(X0[,i]),i]))
}
X[,var_0] <- X0
var_0
which(!apply(X, 2, function(x) sd(x) == 0))
apply(X, 2, function(x) sd(x) == 0)
X
var_0 <- which(!apply(X, 2, function(x) sd(x) == 0))
var_0
var_0 <- which(!apply(X, 2, function(x) sd(x[!is.na(x)]) == 0))
var_0
X_init <- X
var_0 <- which(!apply(X, 2, function(x) sd(x[!is.na(x)]) == 0))
X0 <- X[,var_0]
for(i in var_0){
X0[!is.na(X[,i]),i] <- as.vector(scale(X0[!is.na(X0[,i]),i]))
}
X[,var_0] <- X0
N  <- nrow(X)
r  <- (!is.na(X))*1                                   # r: matrix of responds
Sr <- which(apply(r, 1, function(x) !any(0 %in% x)))  # Sr: responding units
Sm <- which(apply(r, 1, function(x) any(0 %in% x)))   # Sm: nonresponding units
nr <- length(Sr)                                      # nr: number of respondents
nm <- length(Sm)                                      # nm: number of nonrespondents
Rr  <- r[Sm,]                      # r: matrix of responds among the nonrespondents
X[is.na(X)] <- 0
Xr <- as.matrix(X[Sr,])
Xm <- as.matrix(X[Sm,])
if(is.null(d)){ d <- rep(1, N) }
dr <- d[Sr]
dm <- d[Sm]
#-------Variable with at least 2 respondents
TEST <- which(colSums(Rr) != 0)
Xr   <- Xr[,TEST]
Xm   <- Xm[,TEST]
R    <- Rr[,TEST]
J    <- ncol(Xr)
##---Compute the Euclidean distance between respondents and non respondents
if(is.null(w)){ w <- rep(1, J) }
D <- rep(0, nr*nm)
for(i in 1:nm){
D[((i-1)*nr+1):(i*nr)] <- (sqrt(rowSums(t(t(Xr)*R[i,]*w-Xm[i,]*R[i,]*w)^2)))/sum(R[i,])
}
##----------------------------
##  Imputation probabilities
##----------------------------
##---Constraints of calibration
C  <- matrix(rep(0, nr*nm*ncol(Xm)), nrow = ncol(Xm))
for(j in 1:(ncol(Xm))){
C1 <- matrix(rep(0, nr*nm), ncol = nm, nrow = nr)
for(v in 1:nm){
for(u in 1:nr){
C1[u,v] <- dm[v]*R[v,j]*Xr[u,j]
}
}
C[j,] <- as.vector(C1)  # matrix of constraints
}
B1 <- colSums(dm*R*Xm) # matrix of the right hand side of the constraint equation
##---constraints of summing to 1
I <- matrix(rep(0,nr*nm*nm), nrow = nm)
for(v in 1:nm){
I[v,((v-1)*nr+1):(v*nr)] <- 1
}
B2 <- rep(1,nm)
##--- concatenation of the constraints
A <- rbind(C, I)
B <- c(B1, B2)
##---Lpsolve
dir <- rep("=", length(B1)+length(B2))
lp_res <- lpSolve::lp (direction = "min",
objective.in = D,
const.mat = A,
const.dir = dir,
const.rhs = B,
transpose.constraints = TRUE)$solution
d
d <- NULL
if(is.null(d)){ d <- rep(1, N) }
dr <- d[Sr]
dm <- d[Sm]
#-------Variable with at least 2 respondents
TEST <- which(colSums(Rr) != 0)
Xr   <- Xr[,TEST]
Xm   <- Xm[,TEST]
R    <- Rr[,TEST]
J    <- ncol(Xr)
##---Compute the Euclidean distance between respondents and non respondents
if(is.null(w)){ w <- rep(1, J) }
D <- rep(0, nr*nm)
for(i in 1:nm){
D[((i-1)*nr+1):(i*nr)] <- (sqrt(rowSums(t(t(Xr)*R[i,]*w-Xm[i,]*R[i,]*w)^2)))/sum(R[i,])
}
##---Constraints of calibration
C  <- matrix(rep(0, nr*nm*ncol(Xm)), nrow = ncol(Xm))
w <- NULL
##---Compute the Euclidean distance between respondents and non respondents
if(is.null(w)){ w <- rep(1, J) }
D <- rep(0, nr*nm)
for(i in 1:nm){
D[((i-1)*nr+1):(i*nr)] <- (sqrt(rowSums(t(t(Xr)*R[i,]*w-Xm[i,]*R[i,]*w)^2)))/sum(R[i,])
}
##---Constraints of calibration
C  <- matrix(rep(0, nr*nm*ncol(Xm)), nrow = ncol(Xm))
for(j in 1:(ncol(Xm))){
C1 <- matrix(rep(0, nr*nm), ncol = nm, nrow = nr)
for(v in 1:nm){
for(u in 1:nr){
C1[u,v] <- dm[v]*R[v,j]*Xr[u,j]
}
}
C[j,] <- as.vector(C1)  # matrix of constraints
}
B1 <- colSums(dm*R*Xm) # matrix of the right hand side of the constraint equation
##---constraints of summing to 1
I <- matrix(rep(0,nr*nm*nm), nrow = nm)
for(v in 1:nm){
I[v,((v-1)*nr+1):(v*nr)] <- 1
}
B2 <- rep(1,nm)
##--- concatenation of the constraints
A <- rbind(C, I)
B <- c(B1, B2)
##---Lpsolve
dir <- rep("=", length(B1)+length(B2))
lp_res <- lpSolve::lp (direction = "min",
objective.in = D,
const.mat = A,
const.dir = dir,
const.rhs = B,
transpose.constraints = TRUE)$solution
##---constraints of being lower than p
larger <- which(lp_res>(p+eps)) #proba larger than p
larger
lp_res
p+eps
p  <- 1/k
II <- NULL
k <- 3
p  <- 1/k
II <- NULL
##---constraints of being lower than p
larger <- which(lp_res>(p+eps)) #proba larger than p
larger
rep(0, length(larger*nm*nr))
I_tmp  <- matrix(rep(0, length(larger*nm*nr)), nrow = length(larger), ncol = nm*nr)
I_tmp
dim(I_tmp)
matrix(1:4, nrow = 4, ncol = 10)
