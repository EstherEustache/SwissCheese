#' @title Donor imputation of Swiss cheese nonresponse using the cube method
#'
#' @description Impute missing values that have not a particular pattern in a dataset by a donor imputation.
#' It extends the balanced k-nearest neighbors imputation (Hasler and Tille, 2016) to the treatment of the Swiss cheese nonresponse.
#'
#'
#'
#' @param X a matrix with NA values. Rows correspond to units.
#'
#' @param d a vector containing the sampling weights of units. If NULL (default), all sampling weights are equal to 1.
#'
#' @param k the number of neighbors considered to impute each nonrespondent. If NULL (default), the smaller k
#' that makes possible to satisfying calibration equations will be chosen.
#'
#' @param tol a tolerance parameter. Default value is 1e-3.
#'
#' @param max_iter the maximum number of iterations to consider convergence.
#'
#'
#'
#' @details
#' First, the \code{k} nearest neighbors of each nonrespondent are chosen in term of Euclidean distance.
#' Next, imputation probabilities from nearest neighbors of each nonrespondent  are computed satisfying some calibration constraints for all variables simultaneously
#' and to sum to one for each nonrespondent. The method of calibration is based on four requirements (see function \link{calibrate_knn} and package vignette
#' to a complete description of the constraints calibration).
#' Then, the cube method is used to compute the imputation matrix to choose the donors (see (Deville and Tille, 2004)).
#'
#'
#' @references
#' Deville, J. C. and Tille, Y. (2004). Efficient balanced sampling: the cube method. Biometrika, 91(4), 893-912.
#' \emph{Biometrika}, 91(4), 893-912
#'
#' Chauvet, G. and Tille, Y. (2006). A fast algorithm for balanced sampling.
#' \emph{Computational Statistics}, 21(1), 53-62.
#'
#'
#'
#' @return Returns a list including:
#'
#' @return \code{X_imput} the imputed matrix of \code{X}.
#'
#' @return \code{psi} a matrix containing the imputation probabilities considered to imput NA values with the cube method.
#'
#'
#'
#' @author Esther Eustache \email{esther.eustache@@unine.ch}
#'
#'
#'
#' @seealso \link{indKnn}, \link{calibrateKnn}, \link{cubeImput}, \link{linearImput}
#'
#' @examples
#'
#' @export
#'
swissCheeseImput <- function(X, d = NULL, k = NULL, tol = 1e-1, max_iter = 2000)
{
  ##------------------
  ##  Initialization
  ##------------------

  #--- Standardized data
  X_init <- X
  for(i in 1:ncol(X)){
    X[!is.na(X[,i]),i] <- as.vector(scale(X[!is.na(X[,i]),i]))
  }

  N  <- nrow(X)
  S  <- 1:nrow(X)
  r  <- (!is.na(X))*1                                   # r: matrix of responds

  Sr <- which(apply(r, 1, function(x) !any(0 %in% x)))  # Sr: respondent units
  Sm <- which(apply(r, 1, function(x) any(0 %in% x)))   # Sm: nonrespondent units
  nr <- length(Sr)                                      # nr: number of respondents
  nm <- length(Sm)                                      # nm: number of nonrespondents

  R  <- r[Sm,]                      # r: matrix of responds among the nonrespondents

  Xr <- as.matrix(X[Sr,])
  Xm <- as.matrix(X[Sm,])

  if(is.null(d)){ d <- rep(1, N) }
  dr <- d[Sr]
  dm <- d[Sm]

  #-------Variable with at least 2 respondents
  TEST <- which(colSums(R) != 0)
  Xr   <- Xr[,TEST]
  Xm   <- Xm[,TEST]
  R    <- R[,TEST]
  J    <- ncol(X)

  #------Respondents ordering it term of distance with nonrespondent units in rows
  knn   <- indKnn2(Xr, Xm)

  #------k
  k_init <- k
  if (is.null(k)) { k <- 2 } else { k <- min(k,nr) }


  ##-----------------------------------
  ##  First condition for convergence
  ##-----------------------------------
  cvg       <- 0
  donor_max <- rep(0,J)
  tot_m     <- colSums(na.omit(Xm))

  while (cvg == 0) {
    #----Test if k is not to big
    if(k > nr){ stop('The algorithm does not converge. K is bigger than the number of respondents.') }

    knn_k <- knn[,1:k]

    #----Test of the condition
    for(j in 1:J){
      R0_j <- which(R[,j] == 0)
      # donor_j: contains all the possible donors for each variable
      if(sum(R[,j]) != nm){
        donor_j      <- unique(as.vector(knn_k[R0_j,]))
      } else {
        donor_j      <- unique(as.vector(knn_k))
      }
      # select the higgest value for each variable
      donor_max[j] <- max(dr[donor_j]*Xr[donor_j,j])
    }
    if (any(colSums(R)*donor_max < tot_m)) {
      cvg <- 0
      k   <- k+1
    }else{
      cvg <- 1
    }
  }


  ##----------------------------
  ##  Imputation probabilities
  ##----------------------------
  cvg <- 0
  while(cvg == 0){
    psi <- calibrateKnn2(Xr, Xm, dr, dm, knn = knn_k, tol, max_iter)
    if(is.null(psi)){
      k     <- k+1
      if(k > nr){ stop('The algorithm does not converge. k is bigger than the number of respondents.') }
      knn_k <- knn[,1:k]
      cat('k: ',k,'\n')
    } else {
      cvg <- 1
    }
  }
  cat('\n k final: ',k)

  #-------Cube method
  Xm[!R]     <- 0
  X_psi      <- as.vector(t(psi))
  X_strat    <- Xr[as.vector(t(knn_k)),]
  num_strat  <- rep(1:nm, each=k)
  XX         <- matrix(X_psi, ncol=J, nrow=nm*k, byrow=FALSE) * X_strat * R[num_strat,]
  psi_cube   <- balancedStratification(X = XX, pik = X_psi, stratum = num_strat)

  #------Imputed matrix
  Xm_init   <- X_init[Sm,]
  Xm_init[!R]    <- 0
  Xr_init   <- X_init[Sr,]

  psi_cube <- matrix(psi_cube, nrow=k, ncol=nm, byrow=FALSE)
  Xm_init  <- R*Xm_init + (1-R)*Xr_init[knn_k[psi_cube > (1-tol)],]

  X_init[Sm,] <- Xm_init

  if((!is.null(k_init)) && (k>k_init)){ warning('K must have been increased.') }

  return(X_init)
}
